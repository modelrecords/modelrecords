{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Dataset dependencies:\n",
       "- MovieNet: Used to construct the training set for long video tuning, including 400 long movies and corresponding scripts.\n",
       "- MSVD: Used to construct the training set.\n",
       "- MSRVTT: Used to construct the training set.\n",
       "- ActivityNet: Used to construct the training set.\n",
       "- GQA: Used to construct the training set.\n",
       "- MMBench: Used to construct the training set.\n",
       "- MME: Used to construct the training set.\n",
       "- POPE: Used to construct the training set.\n",
       "- SEED: Used to construct the training set.\n",
       "- ScienceQA: Used to construct the training set.\n",
       "- TextVQA: Used to construct the training set.\n",
       "- VizWiz: Used to construct the training set.\n",
       "- VQA V2: Used to construct the training set.\n",
       "\n",
       "Model dependencies:\n",
       "- BERT: Used in the modality alignment stage as it is not pre-trained.\n",
       "- Claude-2: Used to generate plot-related reasoning pairs and detail-related descriptions for long video tuning.\n",
       "- GPT-4: Used to generate summaries and instruction-following data for long video tuning."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from analyzer.utils import build_sentence_window_index, get_openai_api_key, get_sentence_window_query_engine\n",
    "from llama_index.core.response.notebook_utils import display_response\n",
    "\n",
    "api_key = get_openai_api_key()\n",
    "file_path = './analyzer/model-papers/llama-vid.pdf'\n",
    "\n",
    "# Build or load the sentence window index\n",
    "sentence_index = build_sentence_window_index(file_path, api_key)\n",
    "\n",
    "# Get the query engine\n",
    "sentence_window_engine = get_sentence_window_query_engine(sentence_index)\n",
    "\n",
    "query = \"\"\"\n",
    "    Please extract and list all dataset dependencies and model dependencies mentioned in the research paper that were used for training or fine-tuning the main model\n",
    "\n",
    "    - Include pre-trained models that were fine-tuned or further trained as part of the model development process.\n",
    "    - Exclude all datasets and models used solely for validation, testing, evaluation, baseline comparisons or benchmarking. We care about ones that are used for training or fine-tuning.\n",
    "    - For datasets, if a subset was used, list the original, larger dataset as the dependency.\n",
    "    - Provide a brief explanation for each upstream dependency, showing how it was used in the model development. Do not make up a model name.\n",
    "    - Exclude general concepts, libraries, tools, and architectures (e.g., Scikit-learn, Logistic Regression, Variational Autoencoder, Text Transformer, etc).\n",
    "\n",
    "    For instance, if a paper states 'we fine-tuned a pre-trained Model X', then Model X should be listed as a dependency.\n",
    "\n",
    "    Present the information in this format:\n",
    "    Dataset dependencies:\n",
    "    - [Dataset name]: [Brief explanation of its use in training/fine-tuning]\n",
    "    Model dependencies:\n",
    "    - [Model name]: [Brief explanation of its use in training/fine-tuning]\n",
    "\n",
    "    If no relevant datasets or models are identified, state \"None identified\" under the respective category.\n",
    "    DO NOT include any other information in your response.\n",
    "\"\"\"\n",
    "\n",
    "# Query the index\n",
    "window_response = sentence_window_engine.query(query)\n",
    "display_response(window_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Dataset dependencies:\n",
       "- BooksCorpus: Used for pre-training the model on unlabeled data.\n",
       "- English Wikipedia: Used for pre-training the model on unlabeled data.\n",
       "\n",
       "Model dependencies:\n",
       "- OpenAI GPT: Mentioned as a model that introduces minimal task-specific parameters and is fine-tuned on downstream tasks."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = './analyzer/model-papers/bert.pdf'\n",
    "\n",
    "# Build or load the sentence window index\n",
    "sentence_index = build_sentence_window_index(file_path, api_key)\n",
    "\n",
    "# Get the query engine\n",
    "sentence_window_engine = get_sentence_window_query_engine(sentence_index)\n",
    "\n",
    "query = \"\"\"\n",
    "    Please extract and list all dataset dependencies and model dependencies mentioned in the research paper that were used for training or fine-tuning the main model\n",
    "\n",
    "    - Include pre-trained models that were fine-tuned or further trained as part of the model development process.\n",
    "    - Exclude all datasets and models used solely for validation, testing, evaluation, baseline comparisons or benchmarking. We care about ones that are used for training or fine-tuning.\n",
    "    - For datasets, if a subset was used, list the original, larger dataset as the dependency.\n",
    "    - Provide a brief explanation for each upstream dependency, showing how it was used in the model development. Do not make up a model name.\n",
    "    - Exclude general concepts, libraries, tools, and architectures (e.g., Scikit-learn, Logistic Regression, Variational Autoencoder, Text Transformer, etc).\n",
    "\n",
    "    For instance, if a paper states 'we fine-tuned a pre-trained Model X', then Model X should be listed as a dependency.\n",
    "\n",
    "    Present the information in this format:\n",
    "    Dataset dependencies:\n",
    "    - [Dataset name]: [Brief explanation of its use in training/fine-tuning]\n",
    "    Model dependencies:\n",
    "    - [Model name]: [Brief explanation of its use in training/fine-tuning]\n",
    "\n",
    "    If no relevant datasets or models are identified, state \"None identified\" under the respective category.\n",
    "    DO NOT include any other information in your response.\n",
    "\"\"\"\n",
    "\n",
    "# Query the index\n",
    "window_response = sentence_window_engine.query(query)\n",
    "display_response(window_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
