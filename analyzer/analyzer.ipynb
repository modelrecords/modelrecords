{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Dataset dependencies:\n",
       "- LAION-5B: Used to establish the PathLAION collection, which contains pathology image–text data from sources beyond Twitter. This subset was used for training the main model.\n",
       "\n",
       "Model dependencies:\n",
       "- CLIP: Fine-tuned to develop the PLIP model for visual–language representation and learning in pathology."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import build_sentence_window_index, get_openai_api_key, get_sentence_window_query_engine\n",
    "from llama_index.core.response.notebook_utils import display_response\n",
    "\n",
    "api_key = get_openai_api_key()\n",
    "file_path = \"./model-papers/plip.pdf\"\n",
    "\n",
    "# Build or load the sentence window index\n",
    "sentence_index = build_sentence_window_index(file_path, api_key)\n",
    "\n",
    "# Get the query engine\n",
    "sentence_window_engine = get_sentence_window_query_engine(sentence_index)\n",
    "\n",
    "query = \"\"\"\n",
    "    Please extract and list all dataset dependencies and model dependencies mentioned in the research paper that were used for training or fine-tuning the main model\n",
    "\n",
    "    - Include pre-trained models that were fine-tuned or further trained as part of the model development process.\n",
    "    - Exclude all datasets and models used solely for validation, testing, evaluation, baseline comparisons or benchmarking.\n",
    "    - For datasets, if a subset was used, list the original, larger dataset as the dependency.\n",
    "    - Provide a brief explanation for each dependency, showing how it was used in the model development.\n",
    "    - Exclude general concepts, libraries, tools, and architectures (e.g., Scikit-learn, Logistic Regression, Variational Autoencoder, Text Transformer, etc).\n",
    "\n",
    "    For instance, if a paper states 'we fine-tuned a pre-trained Model X', then Model X should be listed as a dependency.\n",
    "\n",
    "    Present the information in this format:\n",
    "    Dataset dependencies:\n",
    "    - [Dataset name]: [Brief explanation of its use in training/fine-tuning]\n",
    "    Model dependencies:\n",
    "    - [Model name]: [Brief explanation of its use in training/fine-tuning]\n",
    "\n",
    "    If no relevant datasets or models are identified, state \"None identified\" under the respective category.\n",
    "    DO NOT include any other information in your response.\n",
    "\"\"\"\n",
    "\n",
    "# Query the index\n",
    "window_response = sentence_window_engine.query(query)\n",
    "display_response(window_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelrecords",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
