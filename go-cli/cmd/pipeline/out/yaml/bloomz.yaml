Additional Information:
- The BLOOMZ & mT0 family includes models of various sizes, suited for different computational
  capabilities and task requirements.
- Performance can significantly vary based on how prompts are structured; experimenting
  with different prompting strategies is recommended for optimal results.
Caveats and Recommendations:
- Prompt engineering is crucial for effective model performance; clear delineation
  of input and desired output helps.
- Providing ample context, especially when requesting outputs in specific languages
  or domains, improves model accuracy.
Ethical Considerations:
- Potential for biased outcomes based on the training data
- Misuse in generating harmful, misleading, or unethical content
Evaluation Data:
  Description: The evaluation data varies across different tasks including coreference
    resolution, natural language inference, program synthesis, and sentence completion,
    with datasets such as Winogrande, XWinograd, ANLI, XNLI, HumanEval, StoryCloze,
    SuperGLUE, and XCOPA.
Factors:
- Language
- Task complexity
Intended Use:
- Natural language understanding and generation across multiple languages
- Crosslingual generalization to unseen tasks and languages
Metrics:
- Accuracy
- Pass@k rates for Program synthesis
Model Details:
  Developed By: BigScience Workshop
  Model Type: Multilingual and Multitask Language Model
  Name: BLOOMZ & mT0
  Release Date: N/A
  Version: N/A
Training Data:
  Description: The model was finetuned on the crosslingual task mixture (xP3), which
    includes data for performing various tasks across multiple languages. For pretraining
    data, refer to the dataset bigscience/xP3.
